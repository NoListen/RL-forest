epoch 0
#############################
eval/Q	0.200833
eval/episodes	20
eval/return	3.0
eval/return_history	3.0
eval/win_rate	0.0
reference_Q_mean	0.164308
reference_Q_std	0.0647281
reference_action_mean	0.0947449
reference_action_std	0.590907
reference_actor_Q_mean	0.194466
reference_actor_Q_std	0.063934
rollout/Q_mean	-0.064777
rollout/actions_mean	-0.0631154
rollout/actions_std	0.357332
rollout/average_return over 100 episodes	13.2791666895
rollout/avergae_return	13.2791666895
rollout/duration	125.70906472206116
rollout/episode_steps	97.05
rollout/episodes	20
total/duration	125.70915079116821
total/episodes	20.0
total/epochs	1
total/steps	1941
total/steps_per_second	15.440403405671296
train/loss_actor	-0.103521
train/loss_critic	0.399432
#############################
epoch 1
#############################
eval/Q	1.03692
eval/episodes	20
eval/return	14.5
eval/return_history	8.75
eval/win_rate	0.0
reference_Q_mean	0.949053
reference_Q_std	0.353654
reference_action_mean	-0.19264
reference_action_std	0.701911
reference_actor_Q_mean	1.0009
reference_actor_Q_std	0.355402
rollout/Q_mean	0.317713
rollout/actions_mean	-0.164482
rollout/actions_std	0.751651
rollout/average_return over 100 episodes	7.28645835519
rollout/avergae_return	1.29375002086
rollout/duration	209.2074899673462
rollout/episode_steps	214.7
rollout/episodes	40
total/duration	334.99149346351624
total/episodes	40.0
total/epochs	2
total/steps	6235
total/steps_per_second	18.612412916923965
train/loss_actor	-0.465618
train/loss_critic	0.197067
#############################
epoch 2
#############################
eval/Q	1.78713
eval/episodes	20
eval/return	20.7791662216
eval/return_history	12.7597220739
eval/win_rate	0.0
reference_Q_mean	2.12811
reference_Q_std	0.823331
reference_action_mean	-0.240715
reference_action_std	0.675667
reference_actor_Q_mean	2.19414
reference_actor_Q_std	0.824634
rollout/Q_mean	1.19598
rollout/actions_mean	-0.313533
rollout/actions_std	0.733144
rollout/average_return over 100 episodes	10.6958332737
rollout/avergae_return	17.5145831108
rollout/duration	222.08854150772095
rollout/episode_steps	142.75
rollout/episodes	60
total/duration	557.1133353710175
total/episodes	60.0
total/epochs	3
total/steps	9090
total/steps_per_second	16.31624917746115
train/loss_actor	-1.12059
train/loss_critic	0.145668
#############################
epoch 0
#############################
eval/Q	0.215775
eval/episodes	20
eval/return	7.25
eval/return_history	7.25
eval/win_rate	0.0
reference_Q_mean	0.170485
reference_Q_std	0.0695664
reference_action_mean	-0.388749
reference_action_std	0.42017
reference_actor_Q_mean	0.224499
reference_actor_Q_std	0.0712497
rollout/Q_mean	-0.0603273
rollout/actions_mean	-0.0282298
rollout/actions_std	0.337764
rollout/average_return over 100 episodes	14.00625
rollout/avergae_return	14.00625
rollout/duration	113.22038197517395
rollout/episode_steps	83.25
rollout/episodes	20
total/duration	113.22045302391052
total/episodes	20.0
total/epochs	1
total/steps	1665
total/steps_per_second	14.705823510955005
train/loss_actor	-0.175062
train/loss_critic	0.778635
#############################
epoch 0
#############################
eval/Q	0.379261
eval/episodes	20
eval/return	61.78125
eval/return_history	61.78125
eval/win_rate	1.0
reference_Q_mean	0.395077
reference_Q_std	0.431059
reference_action_mean	-0.135341
reference_action_std	0.689936
reference_actor_Q_mean	0.4786
reference_actor_Q_std	0.46386
rollout/Q_mean	0.111358
rollout/actions_mean	-0.0749492
rollout/actions_std	0.654649
rollout/average_return over 100 episodes	18.525
rollout/avergae_return	18.525
rollout/duration	493.0045003890991
rollout/episode_steps	281.95
rollout/episodes	20
total/duration	493.0045976638794
total/episodes	20.0
total/epochs	1
total/steps	5639
total/steps_per_second	11.438027204453286
train/loss_actor	-0.215335
train/loss_critic	0.416799
#############################
epoch 1
#############################
eval/Q	1.36696
eval/episodes	20
eval/return	32.13125
eval/return_history	46.95625
eval/win_rate	1.0
reference_Q_mean	1.71012
reference_Q_std	1.28479
reference_action_mean	-0.0240962
reference_action_std	0.736064
reference_actor_Q_mean	1.86064
reference_actor_Q_std	1.2998
rollout/Q_mean	0.973306
rollout/actions_mean	-0.0654108
rollout/actions_std	0.71422
rollout/average_return over 100 episodes	25.984375
rollout/avergae_return	33.44375
rollout/duration	522.550567150116
rollout/episode_steps	289.85
rollout/episodes	40
total/duration	1015.6686718463898
total/episodes	40.0
total/epochs	2
total/steps	11436
total/steps_per_second	11.259577376951512
train/loss_actor	-1.04749
train/loss_critic	0.412872
#############################
epoch 0
#############################
eval/Q	0.860255
eval/episodes	20
eval/return	13.8333337277
eval/return_history	13.8333337277
eval/win_rate	1.0
reference_Q_mean	0.744133
reference_Q_std	0.646889
reference_action_mean	0.591511
reference_action_std	0.582699
reference_actor_Q_mean	0.804232
reference_actor_Q_std	0.66013
rollout/Q_mean	0.258535
rollout/actions_mean	0.195259
rollout/actions_std	0.744467
rollout/average_return over 100 episodes	21.131250149
rollout/avergae_return	21.131250149
rollout/duration	461.2044496536255
rollout/episode_steps	276.5
rollout/episodes	20
total/duration	461.20450925827026
total/episodes	20.0
total/epochs	1
total/steps	5530
total/steps_per_second	11.990342438094531
train/loss_actor	-0.43037
train/loss_critic	0.349387
#############################
epoch 1
#############################
eval/Q	1.59094
eval/episodes	20
eval/return	16.0937502146
eval/return_history	14.9635419711
eval/win_rate	1.0
reference_Q_mean	1.68329
reference_Q_std	1.45436
reference_action_mean	-0.193472
reference_action_std	0.787811
reference_actor_Q_mean	1.80957
reference_actor_Q_std	1.43254
rollout/Q_mean	1.14153
rollout/actions_mean	0.134614
rollout/actions_std	0.757413
rollout/average_return over 100 episodes	20.7208334774
rollout/avergae_return	20.3104168057
rollout/duration	461.9845552444458
rollout/episode_steps	283.75
rollout/episodes	40
total/duration	923.2797558307648
total/episodes	40.0
total/epochs	2
total/steps	11205
total/steps_per_second	12.13608327187654
train/loss_actor	-1.21527
train/loss_critic	0.262457
#############################
epoch 2
#############################
eval/Q	1.94969
eval/episodes	20
eval/return	40.2916667789
eval/return_history	23.4062502404
eval/win_rate	1.0
reference_Q_mean	2.41227
reference_Q_std	2.03952
reference_action_mean	0.0420647
reference_action_std	0.690881
reference_actor_Q_mean	2.51807
reference_actor_Q_std	2.04022
rollout/Q_mean	1.85046
rollout/actions_mean	0.0156371
rollout/actions_std	0.773003
rollout/average_return over 100 episodes	22.3472223192
rollout/avergae_return	25.600000003
rollout/duration	473.6248903274536
rollout/episode_steps	301.65
rollout/episodes	60
total/duration	1396.9467544555664
total/episodes	60.0
total/epochs	3
total/steps	17238
total/steps_per_second	12.339768817257594
train/loss_actor	-2.10182
train/loss_critic	0.251132
#############################
epoch 0
#############################
eval/Q	0.925009
eval/episodes	20
eval/return	16.01875
eval/return_history	16.01875
eval/win_rate	1.0
reference_Q_mean	0.856863
reference_Q_std	0.753747
reference_action_mean	0.219735
reference_action_std	0.657547
reference_actor_Q_mean	0.944371
reference_actor_Q_std	0.770882
rollout/Q_mean	0.324931
rollout/actions_mean	-0.035857
rollout/actions_std	0.765404
rollout/average_return over 100 episodes	30.90625
rollout/avergae_return	30.90625
rollout/duration	427.0809979438782
rollout/episode_steps	277.9
rollout/episodes	20
total/duration	427.0810933113098
total/episodes	20.0
total/epochs	1
total/steps	5558
total/steps_per_second	13.013921915641061
train/loss_actor	-0.498727
train/loss_critic	0.58405
#############################
epoch 1
#############################
eval/Q	2.15009
eval/episodes	20
eval/return	45.85625
eval/return_history	30.9375
eval/win_rate	1.0
reference_Q_mean	2.07789
reference_Q_std	1.94226
reference_action_mean	0.151322
reference_action_std	0.673801
reference_actor_Q_mean	2.19476
reference_actor_Q_std	2.04036
rollout/Q_mean	1.41461
rollout/actions_mean	0.134631
rollout/actions_std	0.767665
rollout/average_return over 100 episodes	38.05625
rollout/avergae_return	45.20625
rollout/duration	468.8256516456604
rollout/episode_steps	284.55
rollout/episodes	40
total/duration	895.9911532402039
total/episodes	40.0
total/epochs	2
total/steps	11249
total/steps_per_second	12.554811461385363
train/loss_actor	-1.49301
train/loss_critic	0.501588
#############################
epoch 0
#############################
eval/Q	0.707376
eval/episodes	20
eval/return	43.1
eval/return_history	43.1
eval/win_rate	1.0
reference_Q_mean	0.626341
reference_Q_std	0.94436
reference_action_mean	0.301052
reference_action_std	0.73903
reference_actor_Q_mean	0.764262
reference_actor_Q_std	0.941489
rollout/Q_mean	0.267097
rollout/actions_mean	-0.00628194
rollout/actions_std	0.762604
rollout/average_return over 100 episodes	25.85
rollout/avergae_return	25.85
rollout/duration	446.63117480278015
rollout/episode_steps	291.25
rollout/episodes	20
total/duration	446.63127970695496
total/episodes	20.0
total/epochs	1
total/steps	5825
total/steps_per_second	13.042078028708415
train/loss_actor	-0.446818
train/loss_critic	0.566966
#############################
epoch 0
#############################
eval/Q	0.692664
eval/episodes	20
eval/return	41.2500000775
eval/return_history	41.2500000775
eval/win_rate	1.0
reference_Q_mean	0.578398
reference_Q_std	0.74391
reference_action_mean	0.169301
reference_action_std	0.841238
reference_actor_Q_mean	0.682186
reference_actor_Q_std	0.745471
rollout/Q_mean	0.188126
rollout/actions_mean	-0.0286289
rollout/actions_std	0.769896
rollout/average_return over 100 episodes	22.9375000492
rollout/avergae_return	22.9375000492
rollout/duration	419.33916211128235
rollout/episode_steps	299.75
rollout/episodes	20
total/duration	419.3392581939697
total/episodes	20.0
total/epochs	1
total/steps	5995
total/steps_per_second	14.296300388901223
train/loss_actor	-0.29805
train/loss_critic	0.240936
#############################
epoch 0
#############################
eval/Q	0.636408
eval/episodes	20
eval/return	40.4020831704
eval/return_history	40.4020831704
eval/win_rate	1.0
reference_Q_mean	0.586001
reference_Q_std	0.55817
reference_action_mean	0.109423
reference_action_std	0.798946
reference_actor_Q_mean	0.712176
reference_actor_Q_std	0.548472
rollout/Q_mean	0.203911
rollout/actions_mean	0.0094918
rollout/actions_std	0.786429
rollout/average_return over 100 episodes	21.7395834178
rollout/avergae_return	21.7395834178
rollout/duration	192.75545954704285
rollout/episode_steps	281.8
rollout/episodes	20
total/duration	192.75556707382202
total/episodes	20.0
total/epochs	1
total/steps	5636
total/steps_per_second	29.23910362517058
train/loss_actor	-0.310857
train/loss_critic	0.286396
#############################
epoch 1
#############################
eval/Q	2.24016
eval/episodes	20
eval/return	32.5083333671
eval/return_history	36.4552082688
eval/win_rate	1.0
reference_Q_mean	2.07496
reference_Q_std	1.45844
reference_action_mean	0.22746
reference_action_std	0.808906
reference_actor_Q_mean	2.25333
reference_actor_Q_std	1.49005
rollout/Q_mean	1.34711
rollout/actions_mean	0.0743822
rollout/actions_std	0.79921
rollout/average_return over 100 episodes	27.5322917178
rollout/avergae_return	33.3250000179
rollout/duration	206.1733992099762
rollout/episode_steps	280.9
rollout/episodes	40
total/duration	399.00823187828064
total/episodes	40.0
total/epochs	2
total/steps	11254
total/steps_per_second	28.204931880786575
train/loss_actor	-1.41554
train/loss_critic	0.251433
#############################
epoch 2
#############################
eval/Q	3.17829
eval/episodes	20
eval/return	29.70833323
eval/return_history	34.2062499225
eval/win_rate	1.0
reference_Q_mean	3.42459
reference_Q_std	2.48168
reference_action_mean	0.286251
reference_action_std	0.831025
reference_actor_Q_mean	3.55589
reference_actor_Q_std	2.50353
rollout/Q_mean	2.88851
rollout/actions_mean	0.263538
rollout/actions_std	0.752833
rollout/average_return over 100 episodes	27.0895833751
rollout/avergae_return	26.2041666895
rollout/duration	384.39993834495544
rollout/episode_steps	269.5
rollout/episodes	60
total/duration	783.4488508701324
total/episodes	60.0
total/epochs	3
total/steps	16644
total/steps_per_second	21.24452666120379
train/loss_actor	-2.84949
train/loss_critic	0.296117
#############################
epoch 0
#############################
eval/Q	2.00364
eval/episodes	10
eval/return	122.837500322
eval/return_history	122.837500322
eval/win_rate	0.1
reference_Q_mean	1.7731
reference_Q_std	1.15499
reference_action_mean	0.435151
reference_action_std	0.647377
reference_actor_Q_mean	1.88334
reference_actor_Q_std	1.18541
rollout/Q_mean	0.744478
rollout/actions_mean	0.0754276
rollout/actions_std	0.744817
rollout/average_return over 100 episodes	76.729166761
rollout/avergae_return	76.729166761
rollout/duration	342.65622305870056
rollout/episode_steps	303.35
rollout/episodes	20
total/duration	342.656334400177
total/episodes	20.0
total/epochs	1
total/steps	6067
total/steps_per_second	17.70578679253176
train/loss_actor	-1.08214
train/loss_critic	0.689729
#############################
epoch 1
#############################
eval/Q	3.81915
eval/episodes	10
eval/return	75.8416666865
eval/return_history	99.3395835042
eval/win_rate	0.0
reference_Q_mean	3.928
reference_Q_std	2.61821
reference_action_mean	0.489308
reference_action_std	0.697061
reference_actor_Q_mean	4.09205
reference_actor_Q_std	2.61794
rollout/Q_mean	2.9814
rollout/actions_mean	0.324454
rollout/actions_std	0.741129
rollout/average_return over 100 episodes	75.9958334029
rollout/avergae_return	75.2625000447
rollout/duration	329.1898112297058
rollout/episode_steps	275.15
rollout/episodes	40
total/duration	671.9398741722107
total/episodes	40.0
total/epochs	2
total/steps	11570
total/steps_per_second	17.2188025219571
train/loss_actor	-2.9384
train/loss_critic	0.684904
#############################
epoch 2
#############################
eval/Q	8.73266
eval/episodes	10
eval/return	87.6374996126
eval/return_history	95.4388888737
eval/win_rate	0.0
reference_Q_mean	6.59145
reference_Q_std	3.90206
reference_action_mean	0.0483515
reference_action_std	0.865881
reference_actor_Q_mean	6.75636
reference_actor_Q_std	3.89057
rollout/Q_mean	6.00623
rollout/actions_mean	0.0792822
rollout/actions_std	0.79305
rollout/average_return over 100 episodes	83.876388972
rollout/avergae_return	99.6375001103
rollout/duration	209.5167577266693
rollout/episode_steps	263.35
rollout/episodes	60
total/duration	881.4982750415802
total/episodes	60.0
total/epochs	3
total/steps	16837
total/steps_per_second	19.100434427062037
train/loss_actor	-5.52874
train/loss_critic	0.798647
#############################
epoch 3
#############################
eval/Q	12.2874
eval/episodes	10
eval/return	54.4416668773
eval/return_history	85.1895833746
eval/win_rate	0.0
reference_Q_mean	8.75483
reference_Q_std	5.01806
reference_action_mean	0.234485
reference_action_std	0.890126
reference_actor_Q_mean	9.03147
reference_actor_Q_std	5.06737
rollout/Q_mean	9.17901
rollout/actions_mean	0.0670994
rollout/actions_std	0.787809
rollout/average_return over 100 episodes	82.2859375462
rollout/avergae_return	77.5145832688
rollout/duration	263.79206252098083
rollout/episode_steps	246.65
rollout/episodes	80
total/duration	1145.3250889778137
total/episodes	80.0
total/epochs	4
total/steps	21770
total/steps_per_second	19.007703759837668
train/loss_actor	-8.26242
train/loss_critic	0.917484
#############################
epoch 4
#############################
eval/Q	17.1368
eval/episodes	10
eval/return	177.433333683
eval/return_history	103.638333436
eval/win_rate	0.0
reference_Q_mean	11.4388
reference_Q_std	6.15823
reference_action_mean	0.24956
reference_action_std	0.866494
reference_actor_Q_mean	11.7808
reference_actor_Q_std	6.22931
rollout/Q_mean	12.7895
rollout/actions_mean	0.0847884
rollout/actions_std	0.784988
rollout/average_return over 100 episodes	91.0012499818
rollout/avergae_return	125.862499724
rollout/duration	291.791640996933
rollout/episode_steps	261.7
rollout/episodes	100
total/duration	1437.1548459529877
total/episodes	100.0
total/epochs	5
total/steps	27004
total/steps_per_second	18.789902894627513
train/loss_actor	-11.4243
train/loss_critic	1.04878
#############################
epoch 5
#############################
eval/Q	22.1298
eval/episodes	10
eval/return	120.129165614
eval/return_history	106.386805466
eval/win_rate	0.0
reference_Q_mean	14.6164
reference_Q_std	7.41043
reference_action_mean	0.363318
reference_action_std	0.83452
reference_actor_Q_mean	14.9373
reference_actor_Q_std	7.4959
rollout/Q_mean	16.4243
rollout/actions_mean	0.143021
rollout/actions_std	0.786277
rollout/average_return over 100 episodes	99.6899999431
rollout/avergae_return	120.172916567
rollout/duration	274.9743676185608
rollout/episode_steps	250.75
rollout/episodes	120
total/duration	1712.169453382492
total/episodes	120.0
total/epochs	6
total/steps	32019
total/steps_per_second	18.700835911273018
train/loss_actor	-14.6077
train/loss_critic	1.26274
#############################
epoch 6
#############################
eval/Q	26.9938
eval/episodes	10
eval/return	207.375
eval/return_history	120.813690399
eval/win_rate	0.0
reference_Q_mean	17.0854
reference_Q_std	8.77532
reference_action_mean	0.42824
reference_action_std	0.81512
reference_actor_Q_mean	17.435
reference_actor_Q_std	8.86143
rollout/Q_mean	18.1356
rollout/actions_mean	0.146877
rollout/actions_std	0.795929
rollout/average_return over 100 episodes	104.504999896
rollout/avergae_return	99.3374998093
rollout/duration	299.36838841438293
rollout/episode_steps	264.65
rollout/episodes	140
total/duration	2011.5596256256104
total/episodes	140.0
total/epochs	7
total/steps	37312
total/steps_per_second	18.548791457472053
train/loss_actor	-17.7375
train/loss_critic	1.3685
#############################
epoch 7
#############################
eval/Q	21.1804
eval/episodes	10
eval/return	72.3375002146
eval/return_history	114.754166626
eval/win_rate	0.0
reference_Q_mean	19.928
reference_Q_std	10.0784
reference_action_mean	0.289366
reference_action_std	0.854789
reference_actor_Q_mean	20.2433
reference_actor_Q_std	10.1506
rollout/Q_mean	22.6585
rollout/actions_mean	0.20194
rollout/actions_std	0.784071
rollout/average_return over 100 episodes	105.768333209
rollout/avergae_return	105.954166678
rollout/duration	298.962539434433
rollout/episode_steps	230.5
rollout/episodes	160
total/duration	2310.5629799365997
total/episodes	160.0
total/epochs	8
total/steps	41922
total/steps_per_second	18.143630086703073
train/loss_actor	-20.6558
train/loss_critic	1.43524
#############################
epoch 8
#############################
eval/Q	24.8335
eval/episodes	10
eval/return	84.9458335638
eval/return_history	111.442129619
eval/win_rate	0.0
reference_Q_mean	21.9656
reference_Q_std	11.2687
reference_action_mean	0.464125
reference_action_std	0.773471
reference_actor_Q_mean	22.4136
reference_actor_Q_std	11.3342
rollout/Q_mean	23.0334
rollout/actions_mean	0.162417
rollout/actions_std	0.795299
rollout/average_return over 100 episodes	103.199166585
rollout/avergae_return	64.668750146
rollout/duration	293.9553129673004
rollout/episode_steps	245.4
rollout/episodes	180
total/duration	2604.5568492412567
total/episodes	180.0
total/epochs	9
total/steps	46830
total/steps_per_second	17.980026050743422
train/loss_actor	-23.408
train/loss_critic	1.63698
#############################
epoch 9
#############################
eval/Q	25.3209
eval/episodes	10
eval/return	85.366666913
eval/return_history	108.834583349
eval/win_rate	0.0
reference_Q_mean	24.3141
reference_Q_std	12.57
reference_action_mean	0.243529
reference_action_std	0.886696
reference_actor_Q_mean	24.8408
reference_actor_Q_std	12.6659
rollout/Q_mean	22.0697
rollout/actions_mean	-0.172073
rollout/actions_std	0.793211
rollout/average_return over 100 episodes	91.9862500107
rollout/avergae_return	69.7979168534
rollout/duration	332.8487391471863
rollout/episode_steps	290.35
rollout/episodes	200
total/duration	2937.4452805519104
total/episodes	200.0
total/epochs	10
total/steps	52637
total/steps_per_second	17.919312522516215
train/loss_actor	-25.8081
train/loss_critic	1.73445
#############################
epoch 10
#############################
eval/Q	20.7902
eval/episodes	10
eval/return	74.0458332896
eval/return_history	103.955416645
eval/win_rate	0.9
reference_Q_mean	25.7203
reference_Q_std	13.6586
reference_action_mean	0.132329
reference_action_std	0.873511
reference_actor_Q_mean	26.2204
reference_actor_Q_std	13.7872
rollout/Q_mean	24.9906
rollout/actions_mean	-0.182833
rollout/actions_std	0.780415
rollout/average_return over 100 episodes	82.8808333498
rollout/avergae_return	74.6458332628
rollout/duration	374.0477283000946
rollout/episode_steps	283.2
rollout/episodes	220
total/duration	3311.535178422928
total/episodes	220.0
total/epochs	11
total/steps	58301
total/steps_per_second	17.60542976558837
train/loss_actor	-27.7832
train/loss_critic	1.91867
#############################
epoch 11
#############################
eval/Q	37.9362
eval/episodes	10
eval/return	133.949999714
eval/return_history	109.766249948
eval/win_rate	0.0
reference_Q_mean	27.9372
reference_Q_std	14.8165
reference_action_mean	0.252652
reference_action_std	0.85704
reference_actor_Q_mean	28.4327
reference_actor_Q_std	14.885
rollout/Q_mean	27.7557
rollout/actions_mean	-0.0950569
rollout/actions_std	0.81754
rollout/average_return over 100 episodes	82.296250025
rollout/avergae_return	96.4145831853
rollout/duration	301.5172061920166
rollout/episode_steps	271.25
rollout/episodes	240
total/duration	3613.077688217163
total/episodes	240.0
total/epochs	12
total/steps	63726
total/steps_per_second	17.6375947319984
train/loss_actor	-29.5757
train/loss_critic	1.84044
#############################
epoch 12
#############################
eval/Q	30.1557
eval/episodes	10
eval/return	88.3291667998
eval/return_history	109.835416667
eval/win_rate	0.1
reference_Q_mean	29.5922
reference_Q_std	15.5708
reference_action_mean	-0.0616844
reference_action_std	0.904732
reference_actor_Q_mean	30.1737
reference_actor_Q_std	15.7119
rollout/Q_mean	29.4118
rollout/actions_mean	-0.19222
rollout/actions_std	0.805078
rollout/average_return over 100 episodes	76.9250000024
rollout/avergae_return	79.0979165643
rollout/duration	329.7595443725586
rollout/episode_steps	285.2
rollout/episodes	260
total/duration	3942.8768599033356
total/episodes	260.0
total/epochs	13
total/steps	69430
total/steps_per_second	17.608969913836507
train/loss_actor	-31.536
train/loss_critic	1.81524
#############################
epoch 13
#############################
eval/Q	40.2608
eval/episodes	10
eval/return	115.19166652
eval/return_history	115.910416631
eval/win_rate	0.0
reference_Q_mean	32.1671
reference_Q_std	16.7627
reference_action_mean	0.133342
reference_action_std	0.878181
reference_actor_Q_mean	32.6774
reference_actor_Q_std	16.8964
rollout/Q_mean	31.6574
rollout/actions_mean	-0.0646104
rollout/actions_std	0.817059
rollout/average_return over 100 episodes	83.4370833004
rollout/avergae_return	97.2291666359
rollout/duration	313.0667471885681
rollout/episode_steps	275.15
rollout/episodes	280
total/duration	4255.971311807632
total/episodes	280.0
total/epochs	14
total/steps	74933
total/steps_per_second	17.606556649502842
train/loss_actor	-33.2077
train/loss_critic	2.10454
#############################
epoch 14
#############################
eval/Q	31.3115
eval/episodes	10
eval/return	103.729166847
eval/return_history	108.539999948
eval/win_rate	0.4
reference_Q_mean	33.1544
reference_Q_std	17.6791
reference_action_mean	0.294961
reference_action_std	0.850824
reference_actor_Q_mean	33.6518
reference_actor_Q_std	17.8113
rollout/Q_mean	28.7619
rollout/actions_mean	-0.0807507
rollout/actions_std	0.818174
rollout/average_return over 100 episodes	85.374999913
rollout/avergae_return	79.4874999166
rollout/duration	366.3278605937958
rollout/episode_steps	312.7
rollout/episodes	300
total/duration	4622.338559627533
total/episodes	300.0
total/epochs	15
total/steps	81187
total/steps_per_second	17.564053120016816
train/loss_actor	-34.5677
train/loss_critic	1.96907
#############################
epoch 15
#############################
eval/Q	55.2744
eval/episodes	10
eval/return	128.404166701
eval/return_history	109.367500056
eval/win_rate	0.0
reference_Q_mean	34.9154
reference_Q_std	18.5763
reference_action_mean	0.21976
reference_action_std	0.853794
reference_actor_Q_mean	35.4209
reference_actor_Q_std	18.7525
rollout/Q_mean	36.7161
rollout/actions_mean	0.0564507
rollout/actions_std	0.815943
rollout/average_return over 100 episodes	87.4970832616
rollout/avergae_return	85.256250006
rollout/duration	313.78697395324707
rollout/episode_steps	252.8
rollout/episodes	320
total/duration	4936.166834115982
total/episodes	320.0
total/epochs	16
total/steps	86243
total/steps_per_second	17.47165420016547
train/loss_actor	-36.0305
train/loss_critic	2.32825
#############################
epoch 16
#############################
eval/Q	49.8913
eval/episodes	10
eval/return	94.4249996066
eval/return_history	98.072500017
eval/win_rate	0.0
reference_Q_mean	36.6627
reference_Q_std	19.5286
reference_action_mean	0.177624
reference_action_std	0.853962
reference_actor_Q_mean	37.1485
reference_actor_Q_std	19.6993
rollout/Q_mean	44.2854
rollout/actions_mean	0.101842
rollout/actions_std	0.796644
rollout/average_return over 100 episodes	83.9845832804
rollout/avergae_return	78.8520832792
rollout/duration	287.2096571922302
rollout/episode_steps	228.45
rollout/episodes	340
total/duration	5223.4009301662445
total/episodes	340.0
total/epochs	17
total/steps	90812
total/steps_per_second	17.385607808801637
train/loss_actor	-37.9244
train/loss_critic	2.41688
#############################
epoch 17
#############################
eval/Q	59.2514
eval/episodes	10
eval/return	80.9166666269
eval/return_history	98.9304166582
eval/win_rate	0.0
reference_Q_mean	37.6609
reference_Q_std	20.5146
reference_action_mean	0.267528
reference_action_std	0.842914
reference_actor_Q_mean	38.3712
reference_actor_Q_std	20.7136
rollout/Q_mean	41.6359
rollout/actions_mean	0.097032
rollout/actions_std	0.811298
rollout/average_return over 100 episodes	86.3208333108
rollout/avergae_return	90.7791667163
rollout/duration	298.1173732280731
rollout/episode_steps	258.6
rollout/episodes	360
total/duration	5521.553389549255
total/episodes	360.0
total/epochs	18
total/steps	95984
total/steps_per_second	17.38351388246479
train/loss_actor	-39.5227
train/loss_critic	2.6054
#############################
epoch 18
#############################
eval/Q	55.4103
eval/episodes	10
eval/return	31.35833323
eval/return_history	93.5716666248
eval/win_rate	0.0
reference_Q_mean	38.7827
reference_Q_std	21.569
reference_action_mean	0.329669
reference_action_std	0.858059
reference_actor_Q_mean	39.5533
reference_actor_Q_std	21.7888
rollout/Q_mean	45.6139
rollout/actions_mean	0.0674412
rollout/actions_std	0.800741
rollout/average_return over 100 episodes	80.8316666555
rollout/avergae_return	69.7833333597
rollout/duration	273.9896123409271
rollout/episode_steps	247.45
rollout/episodes	380
total/duration	5795.579755067825
total/episodes	380.0
total/epochs	19
total/steps	100933
total/steps_per_second	17.415513937452282
train/loss_actor	-41.016
train/loss_critic	2.51657
#############################
epoch 19
#############################
eval/Q	56.5803
eval/episodes	10
eval/return	117.450000334
eval/return_history	96.7799999669
eval/win_rate	0.0
reference_Q_mean	39.6924
reference_Q_std	22.3723
reference_action_mean	0.384131
reference_action_std	0.832741
reference_actor_Q_mean	40.2363
reference_actor_Q_std	22.591
rollout/Q_mean	50.4738
rollout/actions_mean	0.139567
rollout/actions_std	0.794974
rollout/average_return over 100 episodes	81.6512499648
rollout/avergae_return	83.585416463
rollout/duration	251.7306911945343
rollout/episode_steps	219.35
rollout/episodes	400
total/duration	6047.346736431122
total/episodes	400.0
total/epochs	20
total/steps	105320
total/steps_per_second	17.415902310598323
train/loss_actor	-42.6267
train/loss_critic	2.6105
#############################
epoch 0
#############################
eval/Q	2.349
eval/episodes	10
eval/return	112.875
eval/return_history	112.875
eval/win_rate	1.0
reference_Q_mean	1.45754
reference_Q_std	0.955732
reference_action_mean	0.211457
reference_action_std	0.737698
reference_actor_Q_mean	1.63833
reference_actor_Q_std	0.981682
rollout/Q_mean	0.762289
rollout/actions_mean	0.155794
rollout/actions_std	0.741183
rollout/average_return over 100 episodes	80.6895833597
rollout/avergae_return	80.6895833597
rollout/duration	289.7450695037842
rollout/episode_steps	281.15
rollout/episodes	20
total/duration	289.7451765537262
total/episodes	20.0
total/epochs	1
total/steps	5623
total/steps_per_second	19.406707876489367
train/loss_actor	-1.14273
train/loss_critic	0.741999
#############################
