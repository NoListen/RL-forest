epoch 0
#############################
eval/Q	0.66948
eval/episodes	10
eval/return	21.5000000358
eval/return_history	21.5000000358
eval/win_rate	0.0
reference_Q_mean	0.535359
reference_Q_std	0.540982
reference_action_mean	0.585468
reference_action_std	0.594217
reference_actor_Q_mean	0.584484
reference_actor_Q_std	0.543388
rollout/Q_mean	0.158056
rollout/actions_mean	0.0795795
rollout/actions_std	0.767749
rollout/average_return over 100 episodes	18.2125000581
rollout/avergae_return	18.2125000581
rollout/duration	359.1433973312378
rollout/episode_steps	330.1
rollout/episodes	20
total/duration	359.1435446739197
total/episodes	20.0
total/epochs	1
total/steps	6602
total/steps_per_second	18.38262192905127
train/loss_actor	-0.288105
train/loss_critic	0.152066
#############################
epoch 1
#############################
eval/Q	1.20519
eval/episodes	10
eval/return	25.9499998868
eval/return_history	23.7249999613
eval/win_rate	0.0
reference_Q_mean	1.08572
reference_Q_std	1.16708
reference_action_mean	0.602747
reference_action_std	0.547294
reference_actor_Q_mean	1.13464
reference_actor_Q_std	1.18904
rollout/Q_mean	0.955815
rollout/actions_mean	0.360936
rollout/actions_std	0.704027
rollout/average_return over 100 episodes	19.2125000566
rollout/avergae_return	20.2125000551
rollout/duration	342.5323257446289
rollout/episode_steps	283.05
rollout/episodes	40
total/duration	701.7536544799805
total/episodes	40.0
total/epochs	2
total/steps	12263
total/steps_per_second	17.47479321513079
train/loss_actor	-0.844484
train/loss_critic	0.0769702
#############################
epoch 0
#############################
eval/Q	0.664797
eval/episodes	10
eval/return	20.7500000536
eval/return_history	20.7500000536
eval/win_rate	1.0
reference_Q_mean	0.500332
reference_Q_std	0.416574
reference_action_mean	0.489449
reference_action_std	0.673833
reference_actor_Q_mean	0.582699
reference_actor_Q_std	0.43749
rollout/Q_mean	0.160872
rollout/actions_mean	0.0920395
rollout/actions_std	0.752775
rollout/average_return over 100 episodes	17.1062500343
rollout/avergae_return	17.1062500343
rollout/duration	314.3342833518982
rollout/episode_steps	297.65
rollout/episodes	20
total/duration	314.334388256073
total/episodes	20.0
total/epochs	1
total/steps	5953
total/steps_per_second	18.93843060896786
train/loss_actor	-0.249539
train/loss_critic	0.136999
#############################
epoch 1
#############################
eval/Q	2.03751
eval/episodes	10
eval/return	30.6375000209
eval/return_history	25.6937500373
eval/win_rate	1.0
reference_Q_mean	1.44366
reference_Q_std	1.27589
reference_action_mean	0.37325
reference_action_std	0.717692
reference_actor_Q_mean	1.51085
reference_actor_Q_std	1.29275
rollout/Q_mean	1.01253
rollout/actions_mean	0.330217
rollout/actions_std	0.743445
rollout/average_return over 100 episodes	18.593750038
rollout/avergae_return	20.0812500417
rollout/duration	280.8880367279053
rollout/episode_steps	247.75
rollout/episodes	40
total/duration	595.3009784221649
total/episodes	40.0
total/epochs	2
total/steps	10908
total/steps_per_second	18.323504236313315
train/loss_actor	-0.979386
train/loss_critic	0.0747061
#############################
epoch 2
#############################
eval/Q	2.48731
eval/episodes	10
eval/return	21.1875000417
eval/return_history	24.1916667054
eval/win_rate	1.0
reference_Q_mean	2.19341
reference_Q_std	1.91186
reference_action_mean	0.633643
reference_action_std	0.515372
reference_actor_Q_mean	2.27373
reference_actor_Q_std	1.94986
rollout/Q_mean	1.90123
rollout/actions_mean	0.315235
rollout/actions_std	0.73685
rollout/average_return over 100 episodes	19.7479166999
rollout/avergae_return	22.0562500238
rollout/duration	138.81631112098694
rollout/episode_steps	265.8
rollout/episodes	60
total/duration	734.1507925987244
total/episodes	60.0
total/epochs	3
total/steps	16224
total/steps_per_second	22.09900222619223
train/loss_actor	-1.78379
train/loss_critic	0.0737806
#############################
epoch 3
#############################
eval/Q	3.47285
eval/episodes	10
eval/return	21.6250000417
eval/return_history	23.5500000395
eval/win_rate	1.0
reference_Q_mean	3.11276
reference_Q_std	2.62612
reference_action_mean	0.52665
reference_action_std	0.628079
reference_actor_Q_mean	3.19838
reference_actor_Q_std	2.6415
rollout/Q_mean	2.71053
rollout/actions_mean	0.337864
rollout/actions_std	0.693315
rollout/average_return over 100 episodes	20.5375000387
rollout/avergae_return	22.9062500551
rollout/duration	133.85408091545105
rollout/episode_steps	244.05
rollout/episodes	80
total/duration	868.0431883335114
total/episodes	80.0
total/epochs	4
total/steps	21105
total/steps_per_second	24.31330639264372
train/loss_actor	-2.60481
train/loss_critic	0.0798108
#############################
epoch 4
#############################
eval/Q	4.12291
eval/episodes	10
eval/return	20.3125000477
eval/return_history	22.9025000411
eval/win_rate	1.0
reference_Q_mean	3.80957
reference_Q_std	3.23946
reference_action_mean	0.612429
reference_action_std	0.562765
reference_actor_Q_mean	3.88689
reference_actor_Q_std	3.25432
rollout/Q_mean	3.24677
rollout/actions_mean	0.367051
rollout/actions_std	0.703149
rollout/average_return over 100 episodes	20.4362500419
rollout/avergae_return	20.0312500544
rollout/duration	139.59531140327454
rollout/episode_steps	266.6
rollout/episodes	100
total/duration	1007.6721441745758
total/episodes	100.0
total/epochs	5
total/steps	26437
total/steps_per_second	26.235715805814593
train/loss_actor	-3.33863
train/loss_critic	0.0800949
#############################
epoch 5
#############################
eval/Q	4.81369
eval/episodes	10
eval/return	22.5000000536
eval/return_history	22.8354167099
eval/win_rate	1.0
reference_Q_mean	4.39275
reference_Q_std	3.8137
reference_action_mean	0.584719
reference_action_std	0.578794
reference_actor_Q_mean	4.46257
reference_actor_Q_std	3.85357
rollout/Q_mean	3.96091
rollout/actions_mean	0.34462
rollout/actions_std	0.698821
rollout/average_return over 100 episodes	20.9637500454
rollout/avergae_return	19.7437500522
rollout/duration	136.21876096725464
rollout/episode_steps	255.15
rollout/episodes	120
total/duration	1143.911276102066
total/episodes	120.0
total/epochs	6
total/steps	31540
total/steps_per_second	27.572068445267977
train/loss_actor	-4.02801
train/loss_critic	0.0870873
#############################
epoch 6
#############################
eval/Q	5.66645
eval/episodes	10
eval/return	26.4750000149
eval/return_history	23.355357182
eval/win_rate	0.8
reference_Q_mean	5.07497
reference_Q_std	4.33752
reference_action_mean	0.324679
reference_action_std	0.730091
reference_actor_Q_mean	5.16481
reference_actor_Q_std	4.37764
rollout/Q_mean	4.45209
rollout/actions_mean	0.359786
rollout/actions_std	0.705765
rollout/average_return over 100 episodes	20.9937500465
rollout/avergae_return	20.2312500469
rollout/duration	137.14905714988708
rollout/episode_steps	267.85
rollout/episodes	140
total/duration	1281.0812151432037
total/episodes	140.0
total/epochs	7
total/steps	36897
total/steps_per_second	28.801452682198235
train/loss_actor	-4.63164
train/loss_critic	0.0951119
#############################
epoch 7
#############################
eval/Q	6.80061
eval/episodes	10
eval/return	26.4250000134
eval/return_history	23.7390625359
eval/win_rate	0.9
reference_Q_mean	5.65436
reference_Q_std	4.77882
reference_action_mean	-0.161418
reference_action_std	0.847631
reference_actor_Q_mean	5.74582
reference_actor_Q_std	4.79001
rollout/Q_mean	5.09137
rollout/actions_mean	0.111177
rollout/actions_std	0.794872
rollout/average_return over 100 episodes	20.9350000517
rollout/avergae_return	21.7625000499
rollout/duration	142.69644498825073
rollout/episode_steps	272.9
rollout/episodes	160
total/duration	1423.8081727027893
total/episodes	160.0
total/epochs	8
total/steps	42355
total/steps_per_second	29.747687091582197
train/loss_actor	-5.33649
train/loss_critic	0.115126
#############################
epoch 8
#############################
eval/Q	11.4634
eval/episodes	10
eval/return	40.3750000894
eval/return_history	25.5875000419
eval/win_rate	1.0
reference_Q_mean	6.43095
reference_Q_std	5.22841
reference_action_mean	-0.26008
reference_action_std	0.818922
reference_actor_Q_mean	6.51879
reference_actor_Q_std	5.23965
rollout/Q_mean	5.77726
rollout/actions_mean	-0.133806
rollout/actions_std	0.794935
rollout/average_return over 100 episodes	20.6950000523
rollout/avergae_return	21.7062500581
rollout/duration	134.89591479301453
rollout/episode_steps	273.65
rollout/episodes	180
total/duration	1558.738471031189
total/episodes	180.0
total/epochs	9
total/steps	47828
total/steps_per_second	30.68378749153424
train/loss_actor	-6.0367
train/loss_critic	0.129132
#############################
epoch 9
#############################
eval/Q	6.61274
eval/episodes	10
eval/return	28.4250000194
eval/return_history	25.8712500396
eval/win_rate	0.0
reference_Q_mean	6.89258
reference_Q_std	5.63094
reference_action_mean	0.016694
reference_action_std	0.877541
reference_actor_Q_mean	6.97655
reference_actor_Q_std	5.64941
rollout/Q_mean	7.04226
rollout/actions_mean	-0.0337834
rollout/actions_std	0.794321
rollout/average_return over 100 episodes	21.8612500435
rollout/avergae_return	25.8625000104
rollout/duration	157.04017281532288
rollout/episode_steps	274.15
rollout/episodes	200
total/duration	1715.8130700588226
total/episodes	200.0
total/epochs	10
total/steps	53311
total/steps_per_second	31.070400925534596
train/loss_actor	-6.63406
train/loss_critic	0.141387
#############################
epoch 10
#############################
eval/Q	12.3392
eval/episodes	10
eval/return	39.0250000432
eval/return_history	27.6987500386
eval/win_rate	0.9
reference_Q_mean	7.36069
reference_Q_std	6.13288
reference_action_mean	-0.0151266
reference_action_std	0.865273
reference_actor_Q_mean	7.42709
reference_actor_Q_std	6.16125
rollout/Q_mean	7.3072
rollout/actions_mean	0.0162374
rollout/actions_std	0.78371
rollout/average_return over 100 episodes	22.6737500376
rollout/avergae_return	23.8062500224
rollout/duration	136.795268535614
rollout/episode_steps	269.2
rollout/episodes	220
total/duration	1852.6419792175293
total/episodes	220.0
total/epochs	11
total/steps	58695
total/steps_per_second	31.681782372647124
train/loss_actor	-7.21297
train/loss_critic	0.141718
#############################
epoch 11
#############################
eval/Q	12.1182
eval/episodes	10
eval/return	34.8875000671
eval/return_history	28.1237500432
eval/win_rate	0.7
reference_Q_mean	7.98849
reference_Q_std	6.45991
reference_action_mean	-0.00699061
reference_action_std	0.886893
reference_actor_Q_mean	8.07806
reference_actor_Q_std	6.4865
rollout/Q_mean	7.8517
rollout/actions_mean	-0.0256301
rollout/actions_std	0.790397
rollout/average_return over 100 episodes	23.0937500361
rollout/avergae_return	22.3312500395
rollout/duration	145.41704106330872
rollout/episode_steps	282.05
rollout/episodes	240
total/duration	1998.0780284404755
total/episodes	240.0
total/epochs	12
total/steps	64336
total/steps_per_second	32.198942726083146
train/loss_actor	-7.71011
train/loss_critic	0.153601
#############################
epoch 12
#############################
eval/Q	12.9066
eval/episodes	10
eval/return	38.4374999031
eval/return_history	29.8487500294
eval/win_rate	0.8
reference_Q_mean	8.26038
reference_Q_std	6.8528
reference_action_mean	0.146419
reference_action_std	0.871153
reference_actor_Q_mean	8.35323
reference_actor_Q_std	6.89119
rollout/Q_mean	7.83404
rollout/actions_mean	0.053779
rollout/actions_std	0.783244
rollout/average_return over 100 episodes	23.0725000364
rollout/avergae_return	21.6562500514
rollout/duration	264.834499835968
rollout/episode_steps	300.7
rollout/episodes	260
total/duration	2262.952776193619
total/episodes	260.0
total/epochs	13
total/steps	70350
total/steps_per_second	31.087701316653916
train/loss_actor	-7.98154
train/loss_critic	0.156662
#############################
epoch 13
#############################
eval/Q	14.7784
eval/episodes	10
eval/return	38.2000001073
eval/return_history	31.5062500359
eval/win_rate	0.9
reference_Q_mean	8.80827
reference_Q_std	7.30526
reference_action_mean	-0.0709537
reference_action_std	0.901468
reference_actor_Q_mean	8.88107
reference_actor_Q_std	7.34341
rollout/Q_mean	9.04178
rollout/actions_mean	0.00996179
rollout/actions_std	0.803847
rollout/average_return over 100 episodes	23.5425000371
rollout/avergae_return	24.0562500618
rollout/duration	300.6854615211487
rollout/episode_steps	283.9
rollout/episodes	280
total/duration	2563.6757214069366
total/episodes	280.0
total/epochs	14
total/steps	76028
total/steps_per_second	29.65585677047957
train/loss_actor	-8.34976
train/loss_critic	0.18276
#############################
epoch 14
#############################
eval/Q	15.512
eval/episodes	10
eval/return	39.5500000805
eval/return_history	33.4300000392
eval/win_rate	0.9
reference_Q_mean	8.8719
reference_Q_std	7.59423
reference_action_mean	0.0384016
reference_action_std	0.88103
reference_actor_Q_mean	8.96792
reference_actor_Q_std	7.6495
rollout/Q_mean	9.7215
rollout/actions_mean	-0.0396358
rollout/actions_std	0.813338
rollout/average_return over 100 episodes	23.1562500481
rollout/avergae_return	23.9312500656
rollout/duration	292.24682450294495
rollout/episode_steps	279.8
rollout/episodes	300
total/duration	2855.9627647399902
total/episodes	300.0
total/epochs	15
total/steps	81624
total/steps_per_second	28.580204548791144
train/loss_actor	-8.89845
train/loss_critic	0.174277
#############################
epoch 15
#############################
eval/Q	14.0633
eval/episodes	10
eval/return	32.312500076
eval/return_history	34.4112500414
eval/win_rate	1.0
reference_Q_mean	9.28778
reference_Q_std	8.00474
reference_action_mean	0.0423423
reference_action_std	0.913163
reference_actor_Q_mean	9.37452
reference_actor_Q_std	8.04132
rollout/Q_mean	9.59329
rollout/actions_mean	0.026633
rollout/actions_std	0.809828
rollout/average_return over 100 episodes	23.1512500536
rollout/avergae_return	23.7812500499
rollout/duration	308.369752407074
rollout/episode_steps	277.85
rollout/episodes	320
total/duration	3164.3701798915863
total/episodes	320.0
total/epochs	16
total/steps	87181
total/steps_per_second	27.550822136424912
train/loss_actor	-9.16176
train/loss_critic	0.223191
#############################
epoch 16
#############################
eval/Q	14.0816
eval/episodes	10
eval/return	33.4875000909
eval/return_history	35.112500049
eval/win_rate	0.7
reference_Q_mean	9.59388
reference_Q_std	8.34063
reference_action_mean	-0.124921
reference_action_std	0.894253
reference_actor_Q_mean	9.68504
reference_actor_Q_std	8.39075
rollout/Q_mean	8.9083
rollout/actions_mean	-0.0430327
rollout/actions_std	0.797981
rollout/average_return over 100 episodes	22.5875000589
rollout/avergae_return	19.5125000656
rollout/duration	293.94108867645264
rollout/episode_steps	289.35
rollout/episodes	340
total/duration	3458.334003686905
total/episodes	340.0
total/epochs	17
total/steps	92968
total/steps_per_second	26.882308042221336
train/loss_actor	-9.5423
train/loss_critic	0.180604
#############################
epoch 17
#############################
eval/Q	8.78023
eval/episodes	10
eval/return	21.2875000969
eval/return_history	34.5987500574
eval/win_rate	0.0
reference_Q_mean	9.88484
reference_Q_std	8.69435
reference_action_mean	0.00311825
reference_action_std	0.923966
reference_actor_Q_mean	9.9675
reference_actor_Q_std	8.74832
rollout/Q_mean	10.6154
rollout/actions_mean	-0.065676
rollout/actions_std	0.818544
rollout/average_return over 100 episodes	23.2750000589
rollout/avergae_return	25.0937500514
rollout/duration	329.9629397392273
rollout/episode_steps	276.1
rollout/episodes	360
total/duration	3788.3356754779816
total/episodes	360.0
total/epochs	18
total/steps	98490
total/steps_per_second	25.99822413772067
train/loss_actor	-9.80827
train/loss_critic	0.205812
#############################
epoch 18
#############################
eval/Q	10.3717
eval/episodes	10
eval/return	24.5500000015
eval/return_history	33.0162500486
eval/win_rate	1.0
reference_Q_mean	10.1532
reference_Q_std	9.035
reference_action_mean	0.0197329
reference_action_std	0.918292
reference_actor_Q_mean	10.2465
reference_actor_Q_std	9.08872
rollout/Q_mean	11.1271
rollout/actions_mean	-0.0873085
rollout/actions_std	0.795315
rollout/average_return over 100 episodes	23.1137500569
rollout/avergae_return	23.2500000522
rollout/duration	315.1780607700348
rollout/episode_steps	272.6
rollout/episodes	380
total/duration	4103.54497051239
total/episodes	380.0
total/epochs	19
total/steps	103942
total/steps_per_second	25.329806483641693
train/loss_actor	-10.0727
train/loss_critic	0.219165
#############################
epoch 19
#############################
eval/Q	18.2943
eval/episodes	10
eval/return	36.9000000954
eval/return_history	33.8637500562
eval/win_rate	1.0
reference_Q_mean	10.2508
reference_Q_std	9.18994
reference_action_mean	-0.110904
reference_action_std	0.927271
reference_actor_Q_mean	10.3582
reference_actor_Q_std	9.23771
rollout/Q_mean	9.77758
rollout/actions_mean	-0.0280248
rollout/actions_std	0.80686
rollout/average_return over 100 episodes	22.757500052
rollout/avergae_return	22.150000041
rollout/duration	318.43109226226807
rollout/episode_steps	283.55
rollout/episodes	400
total/duration	4422.014704704285
total/episodes	400.0
total/epochs	20
total/steps	109613
total/steps_per_second	24.788022501008438
train/loss_actor	-10.1574
train/loss_critic	0.218087
#############################
epoch 0
#############################
eval/Q	9.83335
eval/episodes	10
eval/return	498.092618339
eval/return_history	498.092618339
eval/win_rate	0.5
reference_Q_mean	8.78714
reference_Q_std	4.81096
reference_action_mean	0.260067
reference_action_std	0.851777
reference_actor_Q_mean	9.19685
reference_actor_Q_std	4.84661
rollout/Q_mean	3.48748
rollout/actions_mean	-0.0860481
rollout/actions_std	0.782557
rollout/average_return over 100 episodes	387.372350037
rollout/avergae_return	387.372350037
rollout/duration	710.3405361175537
rollout/episode_steps	345.7
rollout/episodes	20
total/duration	710.3405909538269
total/episodes	20.0
total/epochs	1
total/steps	6914
total/steps_per_second	9.733359022488157
train/loss_actor	-4.61996
train/loss_critic	2.69605
#############################
epoch 0
#############################
eval/Q	10.2354
eval/episodes	10
eval/return	399.543629104
eval/return_history	399.543629104
eval/win_rate	0.1
reference_Q_mean	6.23125
reference_Q_std	5.4124
reference_action_mean	0.0537243
reference_action_std	0.87961
reference_actor_Q_mean	6.73999
reference_actor_Q_std	5.57889
rollout/Q_mean	3.20943
rollout/actions_mean	-0.119285
rollout/actions_std	0.785083
rollout/average_return over 100 episodes	473.363288975
rollout/avergae_return	473.363288975
rollout/duration	315.2632179260254
rollout/episode_steps	462.05
rollout/episodes	20
total/duration	315.2632825374603
total/episodes	20.0
total/epochs	1
total/steps	9241
total/steps_per_second	29.312008444567162
train/loss_actor	-4.1054
train/loss_critic	3.0177
#############################
epoch 1
#############################
eval/Q	23.7966
eval/episodes	10
eval/return	454.024254256
eval/return_history	426.78394168
eval/win_rate	0.5
reference_Q_mean	14.9823
reference_Q_std	11.6232
reference_action_mean	0.0362948
reference_action_std	0.887166
reference_actor_Q_mean	15.602
reference_actor_Q_std	11.6644
rollout/Q_mean	12.7093
rollout/actions_mean	0.0741872
rollout/actions_std	0.802878
rollout/average_return over 100 episodes	448.169120286
rollout/avergae_return	422.974951598
rollout/duration	221.10562443733215
rollout/episode_steps	372.15
rollout/episodes	40
total/duration	536.4524712562561
total/episodes	40.0
total/epochs	2
total/steps	16684
total/steps_per_second	31.100611692457427
train/loss_actor	-12.211
train/loss_critic	3.32601
#############################
epoch 2
#############################
eval/Q	31.826
eval/episodes	10
eval/return	486.478867811
eval/return_history	446.68225039
eval/win_rate	0.0
reference_Q_mean	23.3491
reference_Q_std	17.8003
reference_action_mean	0.00253429
reference_action_std	0.850295
reference_actor_Q_mean	24.0017
reference_actor_Q_std	18.033
rollout/Q_mean	22.3818
rollout/actions_mean	0.0409615
rollout/actions_std	0.806293
rollout/average_return over 100 episodes	404.031015096
rollout/avergae_return	315.754804715
rollout/duration	327.64747881889343
rollout/episode_steps	317.5
rollout/episodes	60
total/duration	864.1385977268219
total/episodes	60.0
total/epochs	3
total/steps	23034
total/steps_per_second	26.655446314506236
train/loss_actor	-21.9448
train/loss_critic	3.28735
#############################
epoch 3
#############################
eval/Q	45.3212
eval/episodes	10
eval/return	522.232972378
eval/return_history	465.569930887
eval/win_rate	0.0
reference_Q_mean	31.6355
reference_Q_std	24.1251
reference_action_mean	-0.0348561
reference_action_std	0.816612
reference_actor_Q_mean	32.5982
reference_actor_Q_std	24.46
rollout/Q_mean	33.475
rollout/actions_mean	-0.0310095
rollout/actions_std	0.817055
rollout/average_return over 100 episodes	407.859347369
rollout/avergae_return	419.344344188
rollout/duration	324.18003487586975
rollout/episode_steps	335.2
rollout/episodes	80
total/duration	1188.3618500232697
total/episodes	80.0
total/epochs	4
total/steps	29738
total/steps_per_second	25.024364421844822
train/loss_actor	-31.5296
train/loss_critic	4.03593
#############################
epoch 0
#############################
eval/Q	13.927
eval/episodes	10
eval/return	724.881610972
eval/return_history	724.881610972
eval/win_rate	0.5
reference_Q_mean	12.3057
reference_Q_std	9.72674
reference_action_mean	-0.0257936
reference_action_std	0.864986
reference_actor_Q_mean	12.6929
reference_actor_Q_std	9.72743
rollout/Q_mean	4.98384
rollout/actions_mean	-0.0913339
rollout/actions_std	0.791422
rollout/average_return over 100 episodes	607.559537312
rollout/avergae_return	607.559537312
rollout/duration	343.2812316417694
rollout/episode_steps	384.1
rollout/episodes	20
total/duration	343.2812964916229
total/episodes	20.0
total/epochs	1
total/steps	7682
total/steps_per_second	22.378148994748578
train/loss_actor	-5.91347
train/loss_critic	2.74129
#############################
epoch 1
#############################
eval/Q	28.915
eval/episodes	10
eval/return	698.901767908
eval/return_history	711.89168944
eval/win_rate	0.1
reference_Q_mean	25.2267
reference_Q_std	19.2579
reference_action_mean	0.0198083
reference_action_std	0.770136
reference_actor_Q_mean	25.9587
reference_actor_Q_std	19.5809
rollout/Q_mean	19.3423
rollout/actions_mean	-0.0273971
rollout/actions_std	0.822882
rollout/average_return over 100 episodes	626.932964669
rollout/avergae_return	646.306392026
rollout/duration	284.69587993621826
rollout/episode_steps	329.85
rollout/episodes	40
total/duration	628.052731513977
total/episodes	40.0
total/epochs	2
total/steps	14279
total/steps_per_second	22.73535211857004
train/loss_actor	-18.3937
train/loss_critic	2.77063
#############################
epoch 2
#############################
eval/Q	41.5895
eval/episodes	10
eval/return	723.729436141
eval/return_history	715.837605007
eval/win_rate	0.0
reference_Q_mean	37.0293
reference_Q_std	29.2494
reference_action_mean	-0.260391
reference_action_std	0.795814
reference_actor_Q_mean	38.1199
reference_actor_Q_std	29.4244
rollout/Q_mean	33.2738
rollout/actions_mean	0.0154414
rollout/actions_std	0.801038
rollout/average_return over 100 episodes	614.332820731
rollout/avergae_return	589.132532856
rollout/duration	204.69905066490173
rollout/episode_steps	310.4
rollout/episodes	60
total/duration	832.789056301117
total/episodes	60.0
total/epochs	3
total/steps	20487
total/steps_per_second	24.600467363241123
train/loss_actor	-32.1811
train/loss_critic	3.64786
#############################
epoch 3
#############################
eval/Q	55.6001
eval/episodes	10
eval/return	755.166864568
eval/return_history	725.669919897
eval/win_rate	0.1
reference_Q_mean	50.3413
reference_Q_std	37.9925
reference_action_mean	-0.322644
reference_action_std	0.783056
reference_actor_Q_mean	51.4923
reference_actor_Q_std	38.3278
rollout/Q_mean	44.2678
rollout/actions_mean	-0.16086
rollout/actions_std	0.788851
rollout/average_return over 100 episodes	619.398942266
rollout/avergae_return	634.597306871
rollout/duration	344.31952810287476
rollout/episode_steps	325.05
rollout/episodes	80
total/duration	1177.160411119461
total/episodes	80.0
total/epochs	4
total/steps	26988
total/steps_per_second	22.92635714306331
train/loss_actor	-44.9034
train/loss_critic	4.39023
#############################
epoch 0
#############################
eval/Q	12.7142
eval/episodes	10
eval/return	650.231915724
eval/return_history	650.231915724
eval/win_rate	0.0
reference_Q_mean	7.81797
reference_Q_std	8.22249
reference_action_mean	-0.395894
reference_action_std	0.775344
reference_actor_Q_mean	8.1988
reference_actor_Q_std	8.33169
rollout/Q_mean	3.1859
rollout/actions_mean	-0.0309463
rollout/actions_std	0.790857
rollout/average_return over 100 episodes	620.581889936
rollout/avergae_return	620.581889936
rollout/duration	272.1751317977905
rollout/episode_steps	497.8
rollout/episodes	20
total/duration	272.17520236968994
total/episodes	20.0
total/epochs	1
total/steps	9956
total/steps_per_second	36.57937943397566
train/loss_actor	-4.2256
train/loss_critic	3.17819
#############################
epoch 1
#############################
eval/Q	21.7203
eval/episodes	10
eval/return	740.777659714
eval/return_history	695.504787719
eval/win_rate	0.1
reference_Q_mean	17.8832
reference_Q_std	18.4842
reference_action_mean	-0.476847
reference_action_std	0.755819
reference_actor_Q_mean	18.2085
reference_actor_Q_std	18.5422
rollout/Q_mean	14.9227
rollout/actions_mean	-0.211653
rollout/actions_std	0.782321
rollout/average_return over 100 episodes	627.862105688
rollout/avergae_return	635.142321439
rollout/duration	195.87193393707275
rollout/episode_steps	329.8
rollout/episodes	40
total/duration	468.1307113170624
total/episodes	40.0
total/epochs	2
total/steps	16552
total/steps_per_second	35.357646058793655
train/loss_actor	-13.3371
train/loss_critic	2.62019
#############################
epoch 0
#############################
eval/Q	11.8168
eval/episodes	10
eval/return	844.639985606
eval/return_history	844.639985606
eval/win_rate	0.2
reference_Q_mean	8.87047
reference_Q_std	7.3696
reference_action_mean	0.0573277
reference_action_std	0.777734
reference_actor_Q_mean	9.48884
reference_actor_Q_std	7.45879
rollout/Q_mean	3.79784
rollout/actions_mean	0.0941505
rollout/actions_std	0.774342
rollout/average_return over 100 episodes	602.760994104
rollout/avergae_return	602.760994104
rollout/duration	430.11041164398193
rollout/episode_steps	428.65
rollout/episodes	20
total/duration	430.11048889160156
total/episodes	20.0
total/epochs	1
total/steps	8573
total/steps_per_second	19.93208773423009
train/loss_actor	-5.01872
train/loss_critic	2.69119
#############################
epoch 1
#############################
eval/Q	26.1534
eval/episodes	10
eval/return	780.466424549
eval/return_history	812.553205077
eval/win_rate	0.0
reference_Q_mean	22.6208
reference_Q_std	17.9563
reference_action_mean	0.103231
reference_action_std	0.854385
reference_actor_Q_mean	23.8752
reference_actor_Q_std	18.189
rollout/Q_mean	16.6261
rollout/actions_mean	0.0825909
rollout/actions_std	0.814353
rollout/average_return over 100 episodes	657.906181914
rollout/avergae_return	713.051369724
rollout/duration	393.5254247188568
rollout/episode_steps	328.35
rollout/episodes	40
total/duration	823.7164444923401
total/episodes	40.0
total/epochs	2
total/steps	15140
total/steps_per_second	18.380111385697592
train/loss_actor	-16.2101
train/loss_critic	2.78622
#############################
epoch 2
#############################
eval/Q	41.6278
eval/episodes	10
eval/return	917.248739409
eval/return_history	847.451716521
eval/win_rate	0.0
reference_Q_mean	36.8672
reference_Q_std	27.6664
reference_action_mean	-0.116642
reference_action_std	0.893631
reference_actor_Q_mean	37.7819
reference_actor_Q_std	27.7415
rollout/Q_mean	30.3399
rollout/actions_mean	-0.00839793
rollout/actions_std	0.820506
rollout/average_return over 100 episodes	697.260060488
rollout/avergae_return	775.967817637
rollout/duration	424.75674748420715
rollout/episode_steps	364.2
rollout/episodes	60
total/duration	1248.5209665298462
total/episodes	60.0
total/epochs	3
total/steps	22424
total/steps_per_second	17.960451286873884
train/loss_actor	-31.0427
train/loss_critic	3.46163
#############################
epoch 0
#############################
eval/Q	21.0764
eval/episodes	10
eval/return	1078.20815135
eval/return_history	1078.20815135
eval/win_rate	0.0
reference_Q_mean	13.6637
reference_Q_std	9.46212
reference_action_mean	-0.344639
reference_action_std	0.821181
reference_actor_Q_mean	15.0736
reference_actor_Q_std	9.57971
rollout/Q_mean	5.21023
rollout/actions_mean	-0.130594
rollout/actions_std	0.775868
rollout/average_return over 100 episodes	920.504072574
rollout/avergae_return	920.504072574
rollout/duration	243.0905406475067
rollout/episode_steps	464.15
rollout/episodes	20
total/duration	243.090637922287
total/episodes	20.0
total/epochs	1
total/steps	9283
total/steps_per_second	38.18740235881753
train/loss_actor	-6.93224
train/loss_critic	10.7302
#############################
epoch 1
#############################
eval/Q	44.5735
eval/episodes	10
eval/return	1398.50987794
eval/return_history	1238.35901465
eval/win_rate	0.0
reference_Q_mean	32.233
reference_Q_std	23.1095
reference_action_mean	-0.420755
reference_action_std	0.861627
reference_actor_Q_mean	33.588
reference_actor_Q_std	23.2959
rollout/Q_mean	28.8221
rollout/actions_mean	-0.171215
rollout/actions_std	0.79957
rollout/average_return over 100 episodes	956.643329845
rollout/avergae_return	992.782587117
rollout/duration	256.9718098640442
rollout/episode_steps	328.25
rollout/episodes	40
total/duration	500.1447820663452
total/episodes	40.0
total/epochs	2
total/steps	15848
total/steps_per_second	31.68682463210769
train/loss_actor	-25.4535
train/loss_critic	12.6601
#############################
epoch 0
#############################
eval/Q	29.8794
eval/episodes	10
eval/return	1628.56586025
eval/return_history	1628.56586025
eval/win_rate	1.0
reference_Q_mean	23.3881
reference_Q_std	14.3043
reference_action_mean	0.224346
reference_action_std	0.846234
reference_actor_Q_mean	24.1487
reference_actor_Q_std	13.9827
rollout/Q_mean	10.9078
rollout/actions_mean	0.0848549
rollout/actions_std	0.655205
rollout/average_return over 100 episodes	1390.87476198
rollout/avergae_return	1390.87476198
rollout/duration	329.7534396648407
rollout/episode_steps	336.5
rollout/episodes	20
total/duration	329.75352120399475
total/episodes	20.0
total/epochs	1
total/steps	6730
total/steps_per_second	20.409183123890386
train/loss_actor	-12.34
train/loss_critic	10.8857
#############################
epoch 1
#############################
eval/Q	63.1473
eval/episodes	10
eval/return	1711.43720553
eval/return_history	1670.00153289
eval/win_rate	1.0
reference_Q_mean	48.8203
reference_Q_std	33.4583
reference_action_mean	0.0609477
reference_action_std	0.78387
reference_actor_Q_mean	49.8965
reference_actor_Q_std	33.2534
rollout/Q_mean	48.4867
rollout/actions_mean	0.153463
rollout/actions_std	0.768963
rollout/average_return over 100 episodes	1540.88704606
rollout/avergae_return	1690.89933015
rollout/duration	295.0236027240753
rollout/episode_steps	265.0
rollout/episodes	40
total/duration	624.8565926551819
total/episodes	40.0
total/epochs	2
total/steps	12030
total/steps_per_second	19.25241750092022
train/loss_actor	-41.3399
train/loss_critic	12.2697
#############################
epoch 2
#############################
eval/Q	99.5572
eval/episodes	10
eval/return	1741.01855022
eval/return_history	1693.673872
eval/win_rate	0.8
reference_Q_mean	78.8096
reference_Q_std	51.1266
reference_action_mean	0.0870101
reference_action_std	0.844273
reference_actor_Q_mean	80.0853
reference_actor_Q_std	50.779
rollout/Q_mean	78.7049
rollout/actions_mean	0.0745075
rollout/actions_std	0.777873
rollout/average_return over 100 episodes	1536.14010959
rollout/avergae_return	1526.64623665
rollout/duration	287.970139503479
rollout/episode_steps	278.0
rollout/episodes	60
total/duration	912.8577747344971
total/episodes	60.0
total/epochs	3
total/steps	17590
total/steps_per_second	19.26915724096891
train/loss_actor	-75.2592
train/loss_critic	16.7384
#############################
epoch 3
#############################
eval/Q	126.836
eval/episodes	10
eval/return	1706.79751954
eval/return_history	1696.95478388
eval/win_rate	0.8
reference_Q_mean	105.555
reference_Q_std	66.8711
reference_action_mean	0.220631
reference_action_std	0.756084
reference_actor_Q_mean	106.773
reference_actor_Q_std	66.7111
rollout/Q_mean	108.841
rollout/actions_mean	0.208399
rollout/actions_std	0.765517
rollout/average_return over 100 episodes	1548.37499735
rollout/avergae_return	1585.07966061
rollout/duration	318.67819929122925
rollout/episode_steps	291.4
rollout/episodes	80
total/duration	1231.573902130127
total/episodes	80.0
total/epochs	4
total/steps	23418
total/steps_per_second	19.014693279466453
train/loss_actor	-106.538
train/loss_critic	20.4913
#############################
epoch 4
#############################
eval/Q	146.612
eval/episodes	10
eval/return	1499.44392347
eval/return_history	1657.4526118
eval/win_rate	0.6
reference_Q_mean	125.587
reference_Q_std	83.9032
reference_action_mean	0.132086
reference_action_std	0.79654
reference_actor_Q_mean	126.54
reference_actor_Q_std	83.7448
rollout/Q_mean	126.628
rollout/actions_mean	0.11528
rollout/actions_std	0.766145
rollout/average_return over 100 episodes	1548.97357448
rollout/avergae_return	1551.36788301
rollout/duration	327.2195694446564
rollout/episode_steps	325.9
rollout/episodes	100
total/duration	1558.83562874794
total/episodes	100.0
total/epochs	5
total/steps	29936
total/steps_per_second	19.204077356151178
train/loss_actor	-132.967
train/loss_critic	24.7393
#############################
epoch 5
#############################
eval/Q	194.256
eval/episodes	10
eval/return	1654.19840021
eval/return_history	1656.9102432
eval/win_rate	0.9
reference_Q_mean	148.224
reference_Q_std	100.321
reference_action_mean	0.127341
reference_action_std	0.778975
reference_actor_Q_mean	149.309
reference_actor_Q_std	100.268
rollout/Q_mean	154.347
rollout/actions_mean	0.144233
rollout/actions_std	0.714042
rollout/average_return over 100 episodes	1584.3088535
rollout/avergae_return	1567.55115706
rollout/duration	354.04752349853516
rollout/episode_steps	299.7
rollout/episodes	120
total/duration	1912.9219932556152
total/episodes	120.0
total/epochs	6
total/steps	35930
total/steps_per_second	18.782783682072935
train/loss_actor	-158.807
train/loss_critic	28.6528
#############################
epoch 6
#############################
eval/Q	195.158
eval/episodes	10
eval/return	1543.36872234
eval/return_history	1640.69002594
eval/win_rate	0.9
reference_Q_mean	166.887
reference_Q_std	115.228
reference_action_mean	0.116632
reference_action_std	0.809413
reference_actor_Q_mean	168.375
reference_actor_Q_std	115.094
rollout/Q_mean	189.873
rollout/actions_mean	0.203975
rollout/actions_std	0.731284
rollout/average_return over 100 episodes	1559.76843491
rollout/avergae_return	1568.19723721
rollout/duration	351.5599579811096
rollout/episode_steps	279.5
rollout/episodes	140
total/duration	2264.510551929474
total/episodes	140.0
total/epochs	7
total/steps	41520
total/steps_per_second	18.335087891121958
train/loss_actor	-181.943
train/loss_critic	32.4506
#############################
epoch 7
#############################
eval/Q	212.614
eval/episodes	10
eval/return	1515.2711776
eval/return_history	1625.0126699
eval/win_rate	0.8
reference_Q_mean	189.628
reference_Q_std	128.558
reference_action_mean	0.123252
reference_action_std	0.800749
reference_actor_Q_mean	190.943
reference_actor_Q_std	128.26
rollout/Q_mean	207.788
rollout/actions_mean	0.121007
rollout/actions_std	0.747373
rollout/average_return over 100 episodes	1576.23554434
rollout/avergae_return	1608.98178381
rollout/duration	332.2158942222595
rollout/episode_steps	285.45
rollout/episodes	160
total/duration	2596.7781727313995
total/episodes	160.0
total/epochs	8
total/steps	47229
total/steps_per_second	18.187537347605847
train/loss_actor	-206.185
train/loss_critic	35.5088
#############################
epoch 8
#############################
eval/Q	231.434
eval/episodes	10
eval/return	1579.23070709
eval/return_history	1619.92578514
eval/win_rate	0.7
reference_Q_mean	208.349
reference_Q_std	145.179
reference_action_mean	0.187388
reference_action_std	0.788179
reference_actor_Q_mean	210.444
reference_actor_Q_std	144.556
rollout/Q_mean	224.958
rollout/actions_mean	0.156888
rollout/actions_std	0.715643
rollout/average_return over 100 episodes	1550.29537041
rollout/avergae_return	1455.37879095
rollout/duration	320.621844291687
rollout/episode_steps	287.25
rollout/episodes	180
total/duration	2917.4409308433533
total/episodes	180.0
total/epochs	9
total/steps	52974
total/steps_per_second	18.157694107858646
train/loss_actor	-227.123
train/loss_critic	39.4534
#############################
epoch 9
#############################
eval/Q	271.964
eval/episodes	10
eval/return	1666.70412232
eval/return_history	1624.60361886
eval/win_rate	0.4
reference_Q_mean	230.042
reference_Q_std	160.446
reference_action_mean	0.127607
reference_action_std	0.745296
reference_actor_Q_mean	232.748
reference_actor_Q_std	159.721
rollout/Q_mean	249.55
rollout/actions_mean	0.132626
rollout/actions_std	0.716438
rollout/average_return over 100 episodes	1572.42850724
rollout/avergae_return	1662.03356716
rollout/duration	321.02649188041687
rollout/episode_steps	295.15
rollout/episodes	200
total/duration	3238.5102138519287
total/episodes	200.0
total/epochs	10
total/steps	58877
total/steps_per_second	18.180273061412052
train/loss_actor	-248.467
train/loss_critic	40.5457
#############################
