epoch 0
#############################
eval/Q	0.0225689
eval/episodes	20
eval/return	0.073
eval/return_history	0.073
eval/win_rate	0.7
reference_Q_mean	0.0176538
reference_Q_std	0.0201028
reference_action_mean	0.265699
reference_action_std	0.871689
reference_actor_Q_mean	0.018443
reference_actor_Q_std	0.0199
rollout/Q_mean	0.00335197
rollout/actions_mean	0.107724
rollout/actions_std	0.572703
rollout/average_return over 100 episodes	-1.857
rollout/avergae_return	-1.857
rollout/duration	262.62842774391174
rollout/episode_steps	202.75
rollout/episodes	20
total/duration	262.62848114967346
total/episodes	20.0
total/epochs	1
total/steps	4055
total/steps_per_second	15.440061878471713
train/loss_actor	0.00869983
train/loss_critic	0.00304201
#############################
epoch 1
#############################
eval/Q	0.0376496
eval/episodes	20
eval/return	-0.325
eval/return_history	-0.126
eval/win_rate	0.0
reference_Q_mean	0.034611
reference_Q_std	0.0332342
reference_action_mean	0.288227
reference_action_std	0.893546
reference_actor_Q_mean	0.0359645
reference_actor_Q_std	0.0329293
rollout/Q_mean	0.0139992
rollout/actions_mean	0.242948
rollout/actions_std	0.792261
rollout/average_return over 100 episodes	-1.0245
rollout/avergae_return	-0.192
rollout/duration	307.36039638519287
rollout/episode_steps	199.4
rollout/episodes	40
total/duration	570.0443217754364
total/episodes	40.0
total/epochs	2
total/steps	8043
total/steps_per_second	14.109429201837509
train/loss_actor	-0.00432798
train/loss_critic	0.00223409
#############################
epoch 0
#############################
eval/Q	0.0510024
eval/episodes	20
eval/return	0.202
eval/return_history	0.202
eval/win_rate	0.85
reference_Q_mean	0.00967035
reference_Q_std	0.150464
reference_action_mean	0.300932
reference_action_std	0.876809
reference_actor_Q_mean	0.0114904
reference_actor_Q_std	0.149299
rollout/Q_mean	0.00868469
rollout/actions_mean	0.14194
rollout/actions_std	0.585823
rollout/average_return over 100 episodes	-1.465
rollout/avergae_return	-1.465
rollout/duration	284.8584077358246
rollout/episode_steps	194.2
rollout/episodes	20
total/duration	284.8585350513458
total/episodes	20.0
total/epochs	1
total/steps	3884
total/steps_per_second	13.63483807602924
train/loss_actor	-0.00356339
train/loss_critic	8.46348
#############################
epoch 1
#############################
eval/Q	0.0747888
eval/episodes	20
eval/return	0.032
eval/return_history	0.117
eval/win_rate	0.45
reference_Q_mean	0.0376499
reference_Q_std	0.18741
reference_action_mean	0.292931
reference_action_std	0.826033
reference_actor_Q_mean	0.0399872
reference_actor_Q_std	0.187942
rollout/Q_mean	0.0600186
rollout/actions_mean	0.310251
rollout/actions_std	0.879387
rollout/average_return over 100 episodes	-0.6875
rollout/avergae_return	0.09
rollout/duration	294.29341435432434
rollout/episode_steps	209.8
rollout/episodes	40
total/duration	579.2072973251343
total/episodes	40.0
total/epochs	2
total/steps	8080
total/steps_per_second	13.950100486155208
train/loss_actor	-0.055476
train/loss_critic	1.51367
#############################
epoch 2
#############################
eval/Q	0.0408775
eval/episodes	20
eval/return	-0.663
eval/return_history	-0.143
eval/win_rate	0.3
reference_Q_mean	0.0630349
reference_Q_std	0.118771
reference_action_mean	0.178794
reference_action_std	0.848181
reference_actor_Q_mean	0.0683444
reference_actor_Q_std	0.116168
rollout/Q_mean	0.0873134
rollout/actions_mean	0.289869
rollout/actions_std	0.854417
rollout/average_return over 100 episodes	-0.462333333333
rollout/avergae_return	-0.012
rollout/duration	457.78797602653503
rollout/episode_steps	188.35
rollout/episodes	60
total/duration	1037.0097742080688
total/episodes	60.0
total/epochs	3
total/steps	11847
total/steps_per_second	11.42419318954556
train/loss_actor	-0.0857793
train/loss_critic	0.0357815
#############################
epoch 3
#############################
eval/Q	0.0867941
eval/episodes	20
eval/return	-0.08
eval/return_history	-0.12725
eval/win_rate	0.3
reference_Q_mean	0.0824411
reference_Q_std	0.0993462
reference_action_mean	0.236255
reference_action_std	0.916694
reference_actor_Q_mean	0.0850189
reference_actor_Q_std	0.0934297
rollout/Q_mean	0.0748665
rollout/actions_mean	0.289146
rollout/actions_std	0.889879
rollout/average_return over 100 episodes	-0.41325
rollout/avergae_return	-0.266
rollout/duration	269.72928190231323
rollout/episode_steps	202.9
rollout/episodes	80
total/duration	1306.757027387619
total/episodes	80.0
total/epochs	4
total/steps	15905
total/steps_per_second	12.171352184572681
train/loss_actor	-0.094082
train/loss_critic	0.00267661
#############################
epoch 0
#############################
eval/Q	-0.0156967
eval/episodes	20
eval/return	0.555
eval/return_history	0.555
eval/win_rate	1.0
reference_Q_mean	-0.0120745
reference_Q_std	0.00553142
reference_action_mean	-0.211557
reference_action_std	0.784877
reference_actor_Q_mean	-0.0120021
reference_actor_Q_std	0.00549913
rollout/Q_mean	-0.00842678
rollout/actions_mean	-0.0313597
rollout/actions_std	0.401406
rollout/average_return over 100 episodes	-1.452
rollout/avergae_return	-1.452
rollout/duration	204.54186725616455
rollout/episode_steps	195.85
rollout/episodes	20
total/duration	204.5419044494629
total/episodes	20.0
total/epochs	1
total/steps	3917
total/steps_per_second	19.150110147565343
train/loss_actor	0.024325
train/loss_critic	839.915
#############################
epoch 1
#############################
eval/Q	-0.0198288
eval/episodes	20
eval/return	-0.006
eval/return_history	0.2745
eval/win_rate	0.4
reference_Q_mean	-0.0167998
reference_Q_std	0.00812852
reference_action_mean	-0.232968
reference_action_std	0.843379
reference_actor_Q_mean	-0.0167988
reference_actor_Q_std	0.00812796
rollout/Q_mean	-0.0144363
rollout/actions_mean	-0.224418
rollout/actions_std	0.8226
rollout/average_return over 100 episodes	-0.711
rollout/avergae_return	0.03
rollout/duration	262.7863757610321
rollout/episode_steps	202.35
rollout/episodes	40
total/duration	467.3831329345703
total/episodes	40.0
total/epochs	2
total/steps	7964
total/steps_per_second	17.03955371687513
train/loss_actor	0.0181793
train/loss_critic	151.385
#############################
epoch 0
#############################
eval/Q	0.00729553
eval/episodes	20
eval/return	5.55111512313e-18
eval/return_history	5.55111512313e-18
eval/win_rate	0.5
reference_Q_mean	0.00761873
reference_Q_std	0.02104
reference_action_mean	0.29859
reference_action_std	0.533955
reference_actor_Q_mean	0.0110645
reference_actor_Q_std	0.0189313
rollout/Q_mean	0.00497769
rollout/actions_mean	0.0886258
rollout/actions_std	0.415588
rollout/average_return over 100 episodes	-1.721
rollout/avergae_return	-1.721
rollout/duration	270.75547647476196
rollout/episode_steps	193.05
rollout/episodes	20
total/duration	270.75560569763184
total/episodes	20.0
total/epochs	1
total/steps	3861
total/steps_per_second	14.260092565957057
train/loss_actor	-0.0069032
train/loss_critic	0.0024637
#############################
epoch 1
#############################
eval/Q	0.0370363
eval/episodes	20
eval/return	-0.011
eval/return_history	-0.0055
eval/win_rate	0.55
reference_Q_mean	0.0551782
reference_Q_std	0.0786978
reference_action_mean	-0.0209861
reference_action_std	0.784132
reference_actor_Q_mean	0.0597649
reference_actor_Q_std	0.0789132
rollout/Q_mean	0.0229873
rollout/actions_mean	0.027945
rollout/actions_std	0.708415
rollout/average_return over 100 episodes	-0.8535
rollout/avergae_return	0.014
rollout/duration	303.8053524494171
rollout/episode_steps	196.4
rollout/episodes	40
total/duration	574.6258583068848
total/episodes	40.0
total/epochs	2
total/steps	7789
total/steps_per_second	13.55490687966953
train/loss_actor	-0.0308636
train/loss_critic	0.00137645
#############################
epoch 2
#############################
eval/Q	0.0558269
eval/episodes	20
eval/return	-0.107
eval/return_history	-0.0393333333333
eval/win_rate	0.4
reference_Q_mean	0.113273
reference_Q_std	0.096134
reference_action_mean	0.038045
reference_action_std	0.806683
reference_actor_Q_mean	0.115716
reference_actor_Q_std	0.096973
rollout/Q_mean	0.051956
rollout/actions_mean	0.0749335
rollout/actions_std	0.777346
rollout/average_return over 100 episodes	-0.642666666667
rollout/avergae_return	-0.221
rollout/duration	303.86583065986633
rollout/episode_steps	190.85
rollout/episodes	60
total/duration	878.5090706348419
total/episodes	60.0
total/epochs	3
total/steps	11606
total/steps_per_second	13.211018972875364
train/loss_actor	-0.0794897
train/loss_critic	0.00128054
#############################
epoch 3
#############################
eval/Q	0.0882365
eval/episodes	20
eval/return	-0.16
eval/return_history	-0.0695
eval/win_rate	0.3
reference_Q_mean	0.144451
reference_Q_std	0.111232
reference_action_mean	0.107036
reference_action_std	0.850867
reference_actor_Q_mean	0.148391
reference_actor_Q_std	0.111517
rollout/Q_mean	0.082401
rollout/actions_mean	0.239855
rollout/actions_std	0.794168
rollout/average_return over 100 episodes	-0.52725
rollout/avergae_return	-0.181
rollout/duration	318.2427661418915
rollout/episode_steps	204.65
rollout/episodes	80
total/duration	1196.7692213058472
total/episodes	80.0
total/epochs	4
total/steps	15699
total/steps_per_second	13.117817303882644
train/loss_actor	-0.0975127
train/loss_critic	0.00117202
#############################
epoch 4
#############################
eval/Q	0.0885888
eval/episodes	20
eval/return	0.061
eval/return_history	-0.0434
eval/win_rate	0.4
reference_Q_mean	0.145795
reference_Q_std	0.112274
reference_action_mean	0.258995
reference_action_std	0.826271
reference_actor_Q_mean	0.148802
reference_actor_Q_std	0.113037
rollout/Q_mean	0.0659147
rollout/actions_mean	-0.054815
rollout/actions_std	0.823077
rollout/average_return over 100 episodes	-0.4516
rollout/avergae_return	-0.149
rollout/duration	308.00601267814636
rollout/episode_steps	191.7
rollout/episodes	100
total/duration	1504.7930941581726
total/episodes	100.0
total/epochs	5
total/steps	19533
total/steps_per_second	12.980522090266076
train/loss_actor	-0.0925226
train/loss_critic	0.00117741
#############################
