epoch 0
#############################
eval/Q	-0.0947379
eval/episodes	20
eval/return	-0.106
eval/return_history	-0.106
eval/win_rate	0.35
reference_Q_mean	-0.0973166
reference_Q_std	0.0422468
reference_action_mean	0.0613284
reference_action_std	0.0366884
reference_actor_Q_mean	-0.0973166
reference_actor_Q_std	0.0422468
rollout/Q_mean	-0.0316269
rollout/actions_mean	0.0353037
rollout/actions_std	0.194605
rollout/average_return over 100 episodes	-3.804
rollout/avergae_return	-3.804
rollout/duration	306.9011986255646
rollout/episode_steps	208.8
rollout/episodes	20
total/duration	306.9013741016388
total/episodes	20.0
total/epochs	1
total/steps	4176
total/steps_per_second	13.606977199838157
train/loss_actor	0.0588295
train/loss_critic	0.0374865
#############################
epoch 1
#############################
eval/Q	-0.16973
eval/episodes	20
eval/return	-0.075
eval/return_history	-0.0905
eval/win_rate	0.4
reference_Q_mean	-0.176705
reference_Q_std	0.0743651
reference_action_mean	0.0629157
reference_action_std	0.0380603
reference_actor_Q_mean	-0.176705
reference_actor_Q_std	0.0743651
rollout/Q_mean	-0.134842
rollout/actions_mean	0.0623921
rollout/actions_std	0.184695
rollout/average_return over 100 episodes	-3.179
rollout/avergae_return	-2.554
rollout/duration	353.65887808799744
rollout/episode_steps	191.35
rollout/episodes	40
total/duration	660.6071321964264
total/episodes	40.0
total/epochs	2
total/steps	8003
total/steps_per_second	12.114613376018426
train/loss_actor	0.131525
train/loss_critic	0.00325947
#############################
epoch 2
#############################
eval/Q	-0.19373
eval/episodes	20
eval/return	0.03
eval/return_history	-0.0503333333333
eval/win_rate	0.6
reference_Q_mean	-0.207921
reference_Q_std	0.087186
reference_action_mean	0.0661489
reference_action_std	0.0385467
reference_actor_Q_mean	-0.207921
reference_actor_Q_std	0.087186
rollout/Q_mean	-0.183552
rollout/actions_mean	0.0558169
rollout/actions_std	0.201731
rollout/average_return over 100 episodes	-3.106
rollout/avergae_return	-2.96
rollout/duration	322.7773449420929
rollout/episode_steps	200.55
rollout/episodes	60
total/duration	983.4021821022034
total/episodes	60.0
total/epochs	3
total/steps	12014
total/steps_per_second	12.216771752852797
train/loss_actor	0.183778
train/loss_critic	0.00286811
#############################
epoch 3
#############################
eval/Q	-0.217725
eval/episodes	20
eval/return	-0.234
eval/return_history	-0.09625
eval/win_rate	0.3
reference_Q_mean	-0.223043
reference_Q_std	0.0947907
reference_action_mean	0.0850395
reference_action_std	0.0724464
reference_actor_Q_mean	-0.223043
reference_actor_Q_std	0.0947907
rollout/Q_mean	-0.207002
rollout/actions_mean	0.0931712
rollout/actions_std	0.17777
rollout/average_return over 100 episodes	-2.78125
rollout/avergae_return	-1.807
rollout/duration	299.5314242839813
rollout/episode_steps	193.45
rollout/episodes	80
total/duration	1282.9475524425507
total/episodes	80.0
total/epochs	4
total/steps	15883
total/steps_per_second	12.38008519503468
train/loss_actor	0.206302
train/loss_critic	0.00277182
#############################
epoch 4
#############################
eval/Q	-0.204267
eval/episodes	20
eval/return	0.013
eval/return_history	-0.0744
eval/win_rate	0.5
reference_Q_mean	-0.227491
reference_Q_std	0.0959375
reference_action_mean	0.102967
reference_action_std	0.0857485
reference_actor_Q_mean	-0.227491
reference_actor_Q_std	0.0959375
rollout/Q_mean	-0.21235
rollout/actions_mean	0.0967697
rollout/actions_std	0.196554
rollout/average_return over 100 episodes	-2.564
rollout/avergae_return	-1.695
rollout/duration	321.75153160095215
rollout/episode_steps	200.45
rollout/episodes	100
total/duration	1604.7173926830292
total/episodes	100.0
total/epochs	5
total/steps	19892
total/steps_per_second	12.395952141293426
train/loss_actor	0.210201
train/loss_critic	0.00250563
#############################
epoch 5
#############################
eval/Q	-0.202196
eval/episodes	20
eval/return	0.156
eval/return_history	-0.022
eval/win_rate	0.65
reference_Q_mean	-0.220253
reference_Q_std	0.0927485
reference_action_mean	0.119959
reference_action_std	0.102223
reference_actor_Q_mean	-0.220253
reference_actor_Q_std	0.0927485
rollout/Q_mean	-0.199376
rollout/actions_mean	0.112925
rollout/actions_std	0.210077
rollout/average_return over 100 episodes	-2.0258
rollout/avergae_return	-1.113
rollout/duration	342.7726082801819
rollout/episode_steps	205.45
rollout/episodes	120
total/duration	1947.509399175644
total/episodes	120.0
total/epochs	6
total/steps	24001
total/steps_per_second	12.323945656005213
train/loss_actor	0.210642
train/loss_critic	0.00247038
#############################
epoch 6
#############################
eval/Q	-0.186584
eval/episodes	20
eval/return	0.002
eval/return_history	-0.0066
eval/win_rate	0.45
reference_Q_mean	-0.21285
reference_Q_std	0.0896371
reference_action_mean	0.163189
reference_action_std	0.121344
reference_actor_Q_mean	-0.21285
reference_actor_Q_std	0.0896371
rollout/Q_mean	-0.192493
rollout/actions_mean	0.143176
rollout/actions_std	0.221371
rollout/average_return over 100 episodes	-1.6238
rollout/avergae_return	-0.544
rollout/duration	329.27538871765137
rollout/episode_steps	196.8
rollout/episodes	140
total/duration	2276.7963054180145
total/episodes	140.0
total/epochs	7
total/steps	27937
total/steps_per_second	12.270311548520732
train/loss_actor	0.199881
train/loss_critic	0.0023072
#############################
epoch 7
#############################
eval/Q	-0.187551
eval/episodes	20
eval/return	0.053
eval/return_history	-0.002
eval/win_rate	0.55
reference_Q_mean	-0.188169
reference_Q_std	0.0801366
reference_action_mean	0.181705
reference_action_std	0.141451
reference_actor_Q_mean	-0.188169
reference_actor_Q_std	0.0801366
rollout/Q_mean	-0.190911
rollout/actions_mean	0.166788
rollout/actions_std	0.22212
rollout/average_return over 100 episodes	-1.1034
rollout/avergae_return	-0.358
rollout/duration	334.8391079902649
rollout/episode_steps	205.35
rollout/episodes	160
total/duration	2611.6547832489014
total/episodes	160.0
total/epochs	8
total/steps	32044
total/steps_per_second	12.269615496477382
train/loss_actor	0.185185
train/loss_critic	0.00227606
#############################
epoch 8
#############################
eval/Q	-0.164349
eval/episodes	20
eval/return	0.024
eval/return_history	0.0496
eval/win_rate	0.5
reference_Q_mean	-0.172874
reference_Q_std	0.0732598
reference_action_mean	0.186003
reference_action_std	0.144115
reference_actor_Q_mean	-0.172874
reference_actor_Q_std	0.0732598
rollout/Q_mean	-0.165466
rollout/actions_mean	0.185303
rollout/actions_std	0.22248
rollout/average_return over 100 episodes	-0.7802
rollout/avergae_return	-0.191
rollout/duration	324.9951090812683
rollout/episode_steps	204.1
rollout/episodes	180
total/duration	2936.6695561408997
total/episodes	180.0
total/epochs	9
total/steps	36126
total/steps_per_second	12.301690506668193
train/loss_actor	0.167382
train/loss_critic	0.0021927
#############################
epoch 9
#############################
eval/Q	-0.159532
eval/episodes	20
eval/return	0.165
eval/return_history	0.08
eval/win_rate	0.8
reference_Q_mean	-0.157437
reference_Q_std	0.0670813
reference_action_mean	0.22864
reference_action_std	0.160797
reference_actor_Q_mean	-0.157437
reference_actor_Q_std	0.0670813
rollout/Q_mean	-0.160212
rollout/actions_mean	0.209404
rollout/actions_std	0.239489
rollout/average_return over 100 episodes	-0.456
rollout/avergae_return	-0.074
rollout/duration	331.470890045166
rollout/episode_steps	204.35
rollout/episodes	200
total/duration	3268.157475709915
total/episodes	200.0
total/epochs	10
total/steps	40213
total/steps_per_second	12.304486640829587
train/loss_actor	0.152946
train/loss_critic	0.00200257
#############################
epoch 10
#############################
eval/Q	-0.136699
eval/episodes	20
eval/return	0.117
eval/return_history	0.0722
eval/win_rate	0.6
reference_Q_mean	-0.145296
reference_Q_std	0.0629331
reference_action_mean	0.240936
reference_action_std	0.166202
reference_actor_Q_mean	-0.145296
reference_actor_Q_std	0.0629331
rollout/Q_mean	-0.143844
rollout/actions_mean	0.210382
rollout/actions_std	0.244587
rollout/average_return over 100 episodes	-0.2454
rollout/avergae_return	-0.06
rollout/duration	330.7440905570984
rollout/episode_steps	211.3
rollout/episodes	220
total/duration	3598.9162418842316
total/episodes	220.0
total/epochs	11
total/steps	44439
total/steps_per_second	12.347883922059195
train/loss_actor	0.139672
train/loss_critic	0.00176707
#############################
epoch 11
#############################
eval/Q	-0.130549
eval/episodes	20
eval/return	0.282
eval/return_history	0.1282
eval/win_rate	0.8
reference_Q_mean	-0.130432
reference_Q_std	0.0567801
reference_action_mean	0.249891
reference_action_std	0.168805
reference_actor_Q_mean	-0.130432
reference_actor_Q_std	0.0567801
rollout/Q_mean	-0.129749
rollout/actions_mean	0.244209
rollout/actions_std	0.244476
rollout/average_return over 100 episodes	-0.1364
rollout/avergae_return	0.001
rollout/duration	326.77562952041626
rollout/episode_steps	207.55
rollout/episodes	240
total/duration	3925.703177690506
total/episodes	240.0
total/epochs	12
total/steps	48590
total/steps_per_second	12.377400379155903
train/loss_actor	0.127631
train/loss_critic	0.00168477
#############################
epoch 12
#############################
eval/Q	-0.11224
eval/episodes	20
eval/return	0.109
eval/return_history	0.1394
eval/win_rate	0.6
reference_Q_mean	-0.119875
reference_Q_std	0.052579
reference_action_mean	0.253417
reference_action_std	0.172093
reference_actor_Q_mean	-0.119875
reference_actor_Q_std	0.052579
rollout/Q_mean	-0.122032
rollout/actions_mean	0.240425
rollout/actions_std	0.244035
rollout/average_return over 100 episodes	-0.0552
rollout/avergae_return	0.048
rollout/duration	301.12265276908875
rollout/episode_steps	198.7
rollout/episodes	260
total/duration	4226.844899177551
total/episodes	260.0
total/epochs	13
total/steps	52564
total/steps_per_second	12.43575320453035
train/loss_actor	0.116108
train/loss_critic	0.00178704
#############################
epoch 13
#############################
eval/Q	-0.091939
eval/episodes	20
eval/return	0.145
eval/return_history	0.1636
eval/win_rate	0.55
reference_Q_mean	-0.101473
reference_Q_std	0.0453724
reference_action_mean	0.254717
reference_action_std	0.175818
reference_actor_Q_mean	-0.101473
reference_actor_Q_std	0.0453724
rollout/Q_mean	-0.104827
rollout/actions_mean	0.24714
rollout/actions_std	0.251178
rollout/average_return over 100 episodes	-0.0184
rollout/avergae_return	-0.007
rollout/duration	340.0413444042206
rollout/episode_steps	196.75
rollout/episodes	280
total/duration	4566.905714511871
total/episodes	280.0
total/epochs	14
total/steps	56499
total/steps_per_second	12.371396199502847
train/loss_actor	0.099869
train/loss_critic	0.00168283
#############################
epoch 0
#############################
eval/Q	-0.074164
eval/episodes	20
eval/return	0.069
eval/return_history	0.069
eval/win_rate	0.55
reference_Q_mean	-0.0975286
reference_Q_std	0.0283728
reference_action_mean	0.330451
reference_action_std	0.919524
reference_actor_Q_mean	-0.0942834
reference_actor_Q_std	0.0269512
rollout/Q_mean	-0.0337291
rollout/actions_mean	0.10841
rollout/actions_std	0.480878
rollout/average_return over 100 episodes	-3.4795
rollout/avergae_return	-3.4795
rollout/duration	388.9051442146301
rollout/episode_steps	202.4
rollout/episodes	20
total/duration	388.9052720069885
total/episodes	20.0
total/epochs	1
total/steps	4048
total/steps_per_second	10.40870435905857
train/loss_actor	0.0635229
train/loss_critic	0.0414216
#############################
epoch 1
#############################
eval/Q	-0.0891935
eval/episodes	20
eval/return	-0.7195
eval/return_history	-0.32525
eval/win_rate	0.0
reference_Q_mean	-0.108801
reference_Q_std	0.0331372
reference_action_mean	0.249832
reference_action_std	0.873159
reference_actor_Q_mean	-0.106918
reference_actor_Q_std	0.0325359
rollout/Q_mean	-0.0953705
rollout/actions_mean	0.273718
rollout/actions_std	0.855376
rollout/average_return over 100 episodes	-2.21575
rollout/avergae_return	-0.952
rollout/duration	414.39383339881897
rollout/episode_steps	220.1
rollout/episodes	40
total/duration	803.3475630283356
total/episodes	40.0
total/epochs	2
total/steps	8450
total/steps_per_second	10.518485881934458
train/loss_actor	0.0993958
train/loss_critic	0.00223948
#############################
epoch 2
#############################
eval/Q	-0.176643
eval/episodes	20
eval/return	-0.84
eval/return_history	-0.496833333333
eval/win_rate	0.0
reference_Q_mean	-0.176326
reference_Q_std	0.0607571
reference_action_mean	0.282957
reference_action_std	0.893676
reference_actor_Q_mean	-0.175499
reference_actor_Q_std	0.0603401
rollout/Q_mean	-0.129175
rollout/actions_mean	0.220528
rollout/actions_std	0.81853
rollout/average_return over 100 episodes	-1.84866666667
rollout/avergae_return	-1.1145
rollout/duration	402.563618183136
rollout/episode_steps	218.55
rollout/episodes	60
total/duration	1205.9262976646423
total/episodes	60.0
total/epochs	3
total/steps	12821
total/steps_per_second	10.631661341848778
train/loss_actor	0.12269
train/loss_critic	0.00177653
#############################
